{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from AlgoTestFactory import *\n",
    "\n",
    "# altf1 = AlgoTestFactory([0, 10000], 15, savePath=\"Combined_4_test2\", storeAccuracies=True)\n",
    "\n",
    "# altf1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SktWsegRWR_utf8 import *\n",
    "import pickle\n",
    "import ProbData\n",
    "from ProbModels import *\n",
    "import multiprocessing\n",
    "import math\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "goodFileDict = pickle.load(open('mergedGood_v3.p', 'rb'))\n",
    "algo = SktWsegRWR(\n",
    "            w2w_modelFunc = pb.get_w2w_mat, \n",
    "            t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "            v2c_modelFunc = pb.get_v2c_ranking,\n",
    "            sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "            partition=[0.25, 0.25, 0.25, 0.1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSentence(fName, folderTag):\n",
    "        # print('File: ', fName)\n",
    "        try:\n",
    "            dcsObj = pickleFixLoad('../Text Segmentation/DCS_pick/' + fName)           \n",
    "            if folderTag == \"C1020\" :\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/corrected_10to20/' + fName)\n",
    "            else:\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/Pickle_Files/' + fName)\n",
    "\n",
    "        except (KeyError, EOFError, pickle.UnpicklingError) as e:\n",
    "            return None, None\n",
    "        return(sentenceObj, dcsObj)\n",
    "    \n",
    "def Accuracy(prediction, dcsObj):\n",
    "#     solution = [rom_slp(c) for c in dcsObj.dcs_chunks]\n",
    "    solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "#     ac = 100*sum(list(map(lambda x: x in solution, prediction)))/len(prediction)\n",
    "    ac = 100*sum(list(map(lambda x: x in prediction, solution)))/len(solution)\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['5', 'TransitionMat_t2t', 'initialQuery', 'prediction', '3', 'TransitionMat_w2w_samecng', '4', 'DCSLemmas', 'accuracy', 'TransitionMat_w2w', '2', 'nodeList', '1', '0', 'sentence', '6'])\n",
      "\n",
      "dict_keys(['updated_query', 'final_score', 'removed', 'final_rank', 'w2w_samecng_rank', 'w2w_samecng_score', 'w2w_rank', 't2t_score', 't2t_rank', 'w2w_score', 'winner'])\n",
      "[15, 16]\n",
      "[15, 16, 21]\n",
      "[[ 0.040709  0.04046   0.041591  0.041591  0.037939  0.041064  0.041101\n",
      "   0.041317  0.041317  0.041353  0.041227  0.041433  0.041429  0.041316\n",
      "   0.040558  0.031458  0.03466   0.041182  0.041182  0.041182  0.040675\n",
      "   0.037607]]\n",
      "[[15 16 21  4  1 14 20  0  5  6 17 18 19 10 13  8  7  9 12 11  2  3]]\n",
      "\n",
      "[15, 16, 21, 4, 1, 20, 14, 10, 2]\n",
      "[[ 0.040852  0.038907  0.040852  0.040852  0.038907  0.040852  0.040852\n",
      "   0.040852  0.040852  0.040852  0.038907  0.040852  0.040852  0.040852\n",
      "   0.038907  0.038072  0.038907  0.040852  0.040852  0.040852  0.038907\n",
      "   0.038907]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "d = pickle.load(open('.temp/midScore.p','rb'), encoding='utf8')\n",
    "f = d[0]\n",
    "print(f.keys())\n",
    "print()\n",
    "print(f['sentences'])\n",
    "print(f['0'].keys())\n",
    "print(f['initialQuery'])\n",
    "print(f['0']['updated_query'])\n",
    "print(f['0']['final_score'])\n",
    "print(np.asarray(f['0']['final_score'].argsort()))\n",
    "print()\n",
    "print(f['6']['updated_query'])\n",
    "print(f['6']['final_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115527.p \t 100.0\n",
      "115597.p \t 80.0\n",
      "411941.p \t 75.0\n",
      "124269.p \t 66.66666666666667\n",
      "70799.p \t 66.66666666666667\n",
      "441765.p \t 42.857142857142854\n",
      "143751.p \t 100.0\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "for f in list(goodFileDict.keys())[1:10]:\n",
    "# for f in list(goodFileDict.keys())[1:100]:\n",
    "# for f in fullfs[0:1]:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj, verbose = False)\n",
    "        if(result != None):            \n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0]\n",
      "1 [0]\n",
      "Chosen: 1\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'stepDetails' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-bacc5e3c7920>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodFileDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceObj\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/bishal/Documents/summer project/TxSeg_Summer/SktWsegRWR_utf8.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, sentenceObj, dcsObj, verbose)\u001b[0m\n\u001b[0;32m    339\u001b[0m                                             \u001b[0mdeactivate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                         \u001b[0mstepDetails\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'updated_query'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mqu\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'stepDetails' referenced before assignment"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "# for f in list(goodFileDict.keys())[90:91]:\n",
    "for f in list(goodFileDict.keys())[1:100]:\n",
    "# for f in fullfs:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj)\n",
    "        if(result != None):\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "#             print(result)\n",
    "#             print('vs')\n",
    "#             print(solution)\n",
    "#             print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullfs = ['105587.p','293473.p','379245.p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105587.p \t 50.0\n",
      "293473.p \t 66.66666666666667\n",
      "379245.p \t 100.0\n"
     ]
    }
   ],
   "source": [
    "lowScore = []\n",
    "midScore = []\n",
    "highScore = []\n",
    "allOfEm = []\n",
    "np.set_printoptions(precision=4)\n",
    "# for i in range(1, 1000):\n",
    "#     f = list(goodFileDict.keys())[i]\n",
    "# for f in list(goodFileDict.keys())[90:92]:\n",
    "for f in fullfs:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "#         print(f, i)\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        \n",
    "        if(result != None):\n",
    "#             print(runDetails['nodeList'])\n",
    "            ac = runDetails['accuracy']\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "\n",
    "            print(f, '\\t', ac)\n",
    "#             if(ac <= 100):\n",
    "#                 print(result)\n",
    "#                 print('vs')\n",
    "#                 print(solution)\n",
    "#                 pprint.pprint(runDetails['nodeList'])\n",
    "#                 break\n",
    "            # CODE FOR PRINTING RUNDETAILS\n",
    "#             pprint.pprint(runDetails['nodeList'])\n",
    "#             for i in range(runDetails['steps']):\n",
    "#                 if str(i) in runDetails:\n",
    "#                     print('Step', i)\n",
    "#                     step = runDetails[str(i)]\n",
    "#                     pprint.pprint(step['winner'])\n",
    "\n",
    "            # CODE FOR SELECTING FILES \n",
    "#             if(i%100 == 0):\n",
    "#                 print('Chekpoint:', i)\n",
    "#             allOfEm.append((f, ac))\n",
    "#             if(ac <= 40):\n",
    "#                 lowScore.append((f, ac))\n",
    "#             elif (ac <= 60):\n",
    "#                 if(ac >= 50):\n",
    "#                     midScore.append((f, ac))\n",
    "#             elif (ac <= 100):\n",
    "#                 if(ac >= 80):\n",
    "#                     highScore.append((f, ac))\n",
    "\n",
    "# print(len(allOfEm))\n",
    "# print(len(lowScore))\n",
    "# # print(lowScore)\n",
    "# print(len(midScore))\n",
    "# # print(midScore)\n",
    "# print(len(highScore))\n",
    "# # print(highScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKT ANALYZE\n",
      "---------------\n",
      "upacAreRa SIlena rUpayOvanasaMpadA   \n",
      "Analyzing  upacAreRa\n",
      "0 :  upacAreRa ['upacAra'] [{'noun': ['i. sg. m.']}]\n",
      "Analyzing  SIlena\n",
      "0 :  SIlena ['SIla'] [{'noun': ['i. sg. m.', 'i. sg. n.']}]\n",
      "0 :  SIla ['SIla'] [{'compound': ['iic.']}]\n",
      "0 :  SIle ['SIla'] [{'noun': ['loc. sg. m.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.']}]\n",
      "0 :  SIla ['SIl'] [{'verb': ['imp. [1] ac. sg. 2']}]\n",
      "3 :  ina ['na'] [{'noun': ['voc. sg. m.', 'voc. sg. n.']}]\n",
      "4 :  na ['na'] [{'indeclinable': ['part.']}]\n",
      "Analyzing  rUpayOvanasampadA\n",
      "0 :  rUpa ['rUpa'] [{'compound': ['iic.']}]\n",
      "10 :  sampadA ['sampad_2'] [{'noun': ['i. sg. f.']}]\n",
      "4 :  yOvana ['yOvana'] [{'compound': ['iic.']}]\n",
      "4 :  yO ['yu_3'] [{'noun': ['loc. sg. m.', 'loc. sg. f.']}]\n",
      "6 :  vana ['vana'] [{'compound': ['iic.']}]\n",
      "6 :  vana ['van'] [{'verb': ['imp. [1] ac. sg. 2']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SeeSentence(sentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCS ANALYZE\n",
      "---------------\n",
      "upacAreRa SIlena rUpayOvanasaMpadA   \n",
      "[['upacāra'], ['śīla'], ['rūpa', 'yauvana', 'sampad']]\n",
      "Lemmas: ['upacAra', 'SIla', 'rUpa', 'yOvana', 'sampad']\n",
      "[['89'], ['91'], ['3', '3', '90']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SeeDCS(dcsObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lowScore = lowScore[0:10]\n",
    "# midScore = midScore[0:10]\n",
    "# highScore = highScore[0:10]\n",
    "# print(len(lowScore))\n",
    "# print(lowScore)\n",
    "# print(len(midScore))\n",
    "# print(midScore)\n",
    "# print(len(highScore))\n",
    "# print(highScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: 0\n",
      "Checkpoint: 250\n",
      "Checkpoint: 500\n",
      "Checkpoint: 750\n",
      "Checkpoint: 1000\n",
      "Checkpoint: 1250\n",
      "Checkpoint: 1500\n",
      "Checkpoint: 1750\n",
      "Checkpoint: 2000\n",
      "Checkpoint: 2250\n",
      "Checkpoint: 2500\n",
      "Checkpoint: 2750\n",
      "Checkpoint: 3000\n",
      "Checkpoint: 3250\n",
      "Checkpoint: 3500\n",
      "Checkpoint: 3750\n",
      "Checkpoint: 4000\n",
      "Checkpoint: 4250\n",
      "Checkpoint: 4500\n",
      "Checkpoint: 4750\n",
      "Checkpoint: 5000\n",
      "Checkpoint: 5250\n",
      "Checkpoint: 5500\n",
      "Checkpoint: 5750\n",
      "Checkpoint: 6000\n",
      "Checkpoint: 6250\n",
      "Checkpoint: 6500\n",
      "Checkpoint: 6750\n",
      "Checkpoint: 7000\n",
      "Checkpoint: 7250\n",
      "Checkpoint: 7500\n",
      "Checkpoint: 7750\n",
      "Checkpoint: 8000\n",
      "Checkpoint: 8250\n",
      "Checkpoint: 8500\n",
      "Checkpoint: 8750\n",
      "Checkpoint: 9000\n",
      "Checkpoint: 9250\n",
      "Checkpoint: 9500\n",
      "Checkpoint: 9750\n",
      "Checkpoint: 10000\n",
      "Checkpoint: 10250\n",
      "Checkpoint: 10500\n",
      "Checkpoint: 10750\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "# Clean the csv files\n",
    "metPerfFH = open('.temp/metPerfFH.csv', 'w')\n",
    "metPerfFH_bin = open('.temp/metPerfFH_bin.csv', 'w')\n",
    "\n",
    "metPerfFH.write('w2w,t2t,w2w_samecng,InDCS\\n')\n",
    "metPerfFH_bin.write('w2w,t2t,w2w_samecng,InDCS\\n')\n",
    "\n",
    "metPerfFH.close()\n",
    "metPerfFH_bin.close()\n",
    "######################\n",
    "gfl = list(goodFileDict.keys())\n",
    "for i in range(0, 11000):\n",
    "    f = gfl[i]\n",
    "    if(i%250 == 0):\n",
    "        print('Checkpoint:', i)\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        \n",
    "        if(result != None):\n",
    "            solution = [rom_slp(l) for ls in dcsObj.lemmas for l in ls]\n",
    "#             ac = runDetails['accuracy']\n",
    "#             print('Prediction:',result)\n",
    "#             print('DCS:',solution)\n",
    "#             print(f, '\\t', ac)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "jsonBatch = []\n",
    "for f_ in lowScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "pickle.dump(jsonBatch, open('.temp/lowScore.p','wb'))\n",
    "print('33 % Complete')\n",
    "#################################################################\n",
    "jsonBatch = []\n",
    "for f_ in midScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "pickle.dump(jsonBatch, open('.temp/midScore.p','wb'))\n",
    "print('67 % Complete')\n",
    "#################################################################\n",
    "jsonBatch = []\n",
    "for f_ in highScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "print(pprint.pprint(jsonBatch))\n",
    "pickle.dump(jsonBatch, open('.temp/highScore.p','wb'))\n",
    "print('100 % Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = ('super', -23)\n",
    "t2 = ('super', -23)\n",
    "t1 == t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
