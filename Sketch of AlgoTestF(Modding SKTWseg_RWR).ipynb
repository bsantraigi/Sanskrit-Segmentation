{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from AlgoTestFactory import *\n",
    "\n",
    "# altf1 = AlgoTestFactory([0, 10000], 15, savePath=\"Combined_4_test2\", storeAccuracies=True)\n",
    "\n",
    "# altf1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader Started[Prob]...\n",
      "Dataloader Finished[Prob]...\n"
     ]
    }
   ],
   "source": [
    "from SktWsegRWR_utf8 import *\n",
    "import pickle\n",
    "import ProbData\n",
    "from ProbModels import *\n",
    "import multiprocessing\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "goodFileDict = pickle.load(open('mergedGood_v3.p', 'rb'))\n",
    "algo = SktWsegRWR(\n",
    "            w2w_modelFunc = pb.get_w2w_mat, \n",
    "            t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "            v2c_modelFunc = pb.get_v2c_ranking,\n",
    "            sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "            partition=[0.25, 0.25, 0.25, 0.1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSentence(fName, folderTag):\n",
    "        # print('File: ', fName)\n",
    "        try:\n",
    "            dcsObj = pickleFixLoad('../Text Segmentation/DCS_pick/' + fName)           \n",
    "            if folderTag == \"C1020\" :\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/corrected_10to20/' + fName)\n",
    "            else:\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/Pickle_Files/' + fName)\n",
    "\n",
    "        except (KeyError, EOFError, pickle.UnpicklingError) as e:\n",
    "            return None, None\n",
    "        return(sentenceObj, dcsObj)\n",
    "    \n",
    "def Accuracy(prediction, dcsObj):\n",
    "#     solution = [rom_slp(c) for c in dcsObj.dcs_chunks]\n",
    "    solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "#     ac = 100*sum(list(map(lambda x: x in solution, prediction)))/len(prediction)\n",
    "    ac = 100*sum(list(map(lambda x: x in prediction, solution)))/len(solution)\n",
    "    if(ac >= 100):\n",
    "        if(len(result) != len(solution)):\n",
    "            print(result)\n",
    "            print('vs')\n",
    "            print(solution)\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullfs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438972.p \t 100.0\n",
      "['tatra', 'yama', 'yama']\n",
      "vs\n",
      "['tatra', 'yama']\n",
      "286896.p \t 100.0\n",
      "['bala', 'tatra', 'sTA', 'han', 'pARqava', 'Seza', 'Ana']\n",
      "vs\n",
      "['han', 'Seza', 'bala', 'tatra', 'pARqava', 'sTA']\n",
      "406292.p \t 100.0\n",
      "297156.p \t 100.0\n",
      "['datta', 'DAraRa', 'dA']\n",
      "vs\n",
      "['dA', 'DAraRa']\n",
      "394396.p \t 100.0\n",
      "190197.p \t 100.0\n",
      "310440.p \t 100.0\n",
      "['kf', 'vrata', 'ca', 'kf', 'a', 'dA', 'strI', 'vrata', 'brU', 'Ama']\n",
      "vs\n",
      "['strI', 'brU', 'vrata', 'kf', 'dA', 'ca', 'kf', 'vrata']\n",
      "428339.p \t 100.0\n",
      "139440.p \t 100.0\n",
      "425436.p \t 100.0\n",
      "188400.p \t 100.0\n",
      "['na', 'Svan', 'an']\n",
      "vs\n",
      "['na', 'Svan']\n",
      "354087.p \t 100.0\n",
      "376053.p \t 100.0\n",
      "401942.p \t 100.0\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "# for f in list(goodFileDict.keys())[90:91]:\n",
    "# for f in list(goodFileDict.keys())[1:100]:\n",
    "for f in fullfs:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj)\n",
    "        if(result != None):\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "#             print(result)\n",
    "            print(f, \"\\t\", ac)\n",
    "#             if(ac == 100):\n",
    "#                 fullfs.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasmiMstu tumule yudDe BIrURAM BayavarDane   \n",
      "Analyzing  tasmiMstu\n",
      "0 :  tasmin ['tad'] [{'noun': ['loc. sg. n.', 'loc. sg. m.']}]\n",
      "7 :  tu ['tu'] [{'indeclinable': ['conj.']}]\n",
      "Analyzing  tumule\n",
      "0 :  tumule ['tumula'] [{'noun': ['loc. sg. m.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.', 'acc. du. f.', 'nom. du. f.']}]\n",
      "0 :  tumule ['tumula'] [{'noun': ['voc. du. n.', 'voc. du. f.', 'voc. sg. f.']}]\n",
      "Analyzing  yudDe\n",
      "0 :  yudDe ['yudDa', 'yuD_1'] [{'noun': ['acc. du. f.', 'nom. du. f.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.', 'loc. sg. m.']}, {'verb': ['pp.']}]\n",
      "0 :  yudDe ['yudDa', 'yuD_1'] [{'noun': ['voc. du. f.', 'voc. sg. f.', 'voc. du. n.']}, {'verb': ['pp.']}]\n",
      "0 :  yut ['yuD_2'] [{'compound': ['iic.']}]\n",
      "0 :  yut ['yuD_2'] [{'noun': ['nom. sg. m.', 'nom. sg. f.']}]\n",
      "3 :  De ['DA_3', 'DI_2'] [{'noun': ['dat. sg. m.', 'acc. du. f.', 'nom. du. f.']}, {'noun': ['loc. sg. m.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.']}]\n",
      "3 :  he ['he'] [{'undetermined': ['und.']}]\n",
      "Analyzing  BIrURAm\n",
      "0 :  BIrURAm ['BIru'] [{'noun': ['g. pl. m.', 'g. pl. n.', 'g. pl. f.']}]\n",
      "Analyzing  BayavarDane\n",
      "0 :  Baya ['Baya'] [{'compound': ['iic.']}]\n",
      "4 :  varDane ['varDana'] [{'noun': ['loc. sg. m.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.']}]\n",
      "4 :  varDane ['varDana'] [{'noun': ['voc. du. n.']}]\n"
     ]
    }
   ],
   "source": [
    "SeeSentence(sentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tasmiMstu tumule yudDe BIrURAM BayavarDane   \n",
      "[['tad', 'tu'], ['tumula'], ['yuddha'], ['bhÄ«ru'], ['bhaya', 'vardhana']]\n",
      "Lemmas: ['tad', 'tu', 'tumula', 'yudDa', 'BIru', 'Baya', 'varDana']\n",
      "[['171', '2'], ['171'], ['171'], ['159'], ['3', '171']]\n"
     ]
    }
   ],
   "source": [
    "SeeDCS(dcsObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'327359.p'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(goodFileDict.keys())[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['179084.p',\n",
       " '212470.p',\n",
       " '141314.p',\n",
       " '312382.p',\n",
       " '371565.p',\n",
       " '20967.p',\n",
       " '178347.p',\n",
       " '289080.p',\n",
       " '334071.p',\n",
       " '407484.p',\n",
       " '209444.p']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7941\n",
    "# Results: \n",
    "# Mean:  65.7963242743\n",
    "# Percentiles:  [   5.88   50.     66.67   85.71  100.  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
