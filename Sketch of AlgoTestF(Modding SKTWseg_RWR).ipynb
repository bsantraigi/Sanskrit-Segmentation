{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from AlgoTestFactory import *\n",
    "\n",
    "# altf1 = AlgoTestFactory([0, 10000], 15, savePath=\"Combined_4_test2\", storeAccuracies=True)\n",
    "\n",
    "# altf1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader Started[Prob]...\n",
      "Dataloader Finished[Prob]...\n"
     ]
    }
   ],
   "source": [
    "from SktWsegRWR_utf8 import *\n",
    "import pickle\n",
    "import ProbData\n",
    "from ProbModels import *\n",
    "import multiprocessing\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "goodFileDict = pickle.load(open('mergedGood_v3.p', 'rb'))\n",
    "algo = SktWsegRWR(\n",
    "            w2w_modelFunc = pb.get_w2w_mat, \n",
    "            t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "            v2c_modelFunc = pb.get_v2c_ranking,\n",
    "            sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "            partition=[0.25, 0.25, 0.25, 0.1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSentence(fName, folderTag):\n",
    "        # print('File: ', fName)\n",
    "        try:\n",
    "            dcsObj = pickleFixLoad('../Text Segmentation/DCS_pick/' + fName)           \n",
    "            if folderTag == \"C1020\" :\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/corrected_10to20/' + fName)\n",
    "            else:\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/Pickle_Files/' + fName)\n",
    "\n",
    "        except (KeyError, EOFError, pickle.UnpicklingError) as e:\n",
    "            return None, None\n",
    "        return(sentenceObj, dcsObj)\n",
    "    \n",
    "def Accuracy(prediction, dcsObj):\n",
    "#     solution = [rom_slp(c) for c in dcsObj.dcs_chunks]\n",
    "    solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "#     ac = 100*sum(list(map(lambda x: x in solution, prediction)))/len(prediction)\n",
    "    ac = 100*sum(list(map(lambda x: x in prediction, solution)))/len(solution)\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullfs = ['60449.p','164056.p','379245.p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tad', 'arDa', 'tad', 'eva', 'as', 'dA', 'rAjya']\n",
      "vs\n",
      "['maDura', 'eva', 'rAjya', 'tad', 'arDa', 'pradA']\n",
      "164056.p \t 66.66666666666667\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "# for f in list(goodFileDict.keys())[90:91]:\n",
    "# for f in list(goodFileDict.keys())[1:100]:\n",
    "for f in fullfs[1:2]:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj)\n",
    "        if(result != None):\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "            print(result)\n",
    "            print('vs')\n",
    "            print(solution)\n",
    "            print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner: sa <- tad\n",
      "Remove: sarasas\n",
      "Remove: sarasas\n",
      "Remove: sara\n",
      "Remove: rasas\n",
      "Remove: sas\n",
      "Winner: BAvam <- BU\n",
      "('BAvam', 'B') ('m', 'BAvam')\n",
      "('BA', 'B') ('A', 'BA')\n",
      "('Avam', 'A') ('m', 'Avam')\n",
      "Winner: cakra <- kf\n",
      "Remove: me\n",
      "Remove: cakrame\n",
      "Winner: praBAvam <- praBAva\n",
      "Remove: praBA\n",
      "('Avam', 'A') ('m', 'Avam')\n",
      "Winner: KyAtum <- KyA\n",
      "Winner: Avam <- av\n",
      "60449.p \t 40.0\n",
      "Winner: tAm <- tad\n",
      "('tAm', 't') ('m', 'tAm')\n",
      "('tAm', 't') ('m', 'tAm')\n",
      "('tAm', 't') ('m', 'tAm')\n",
      "Remove: dIya\n",
      "Winner: eva <- eva\n",
      "('a', 'e') ('a', 'e')\n",
      "maDureRa eva ('a', 'e')  =  {'derivations': ['E'], 'length': 1}\n",
      "Remove: maDureRa\n",
      "Remove: maDu\n",
      "('a', 'e') ('a', 'e')\n",
      "reRa eva ('a', 'e')  =  {'derivations': ['E'], 'length': 1}\n",
      "Remove: reRa\n",
      "Remove: Eva\n",
      "Winner: asya <- as\n",
      "('asya', 'a') ('a', 'asya')\n",
      "('asya', 'a') ('a', 'asya')\n",
      "('asya', 'a') ('a', 'asya')\n",
      "('asya', 'a') ('a', 'asya')\n",
      "('asya', 'a') ('a', 'asya')\n",
      "Remove: rAji\n",
      "Remove: rAjI\n",
      "Remove: rAjI\n",
      "Remove: asya\n",
      "Winner: dIyatAm <- dA\n",
      "Remove: dIyatAm\n",
      "Remove: dIyatAm\n",
      "Winner: rAjyasya <- rAjya\n",
      "Remove: rAjyasya\n",
      "Remove: rAjyasya\n",
      "Remove: rAjyasya\n",
      "Remove: rAjyasya\n",
      "164056.p \t 66.66666666666667\n",
      "Winner: prItas <- prI\n",
      "Remove: prItas\n",
      "379245.p \t 100.0\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "# for f in list(goodFileDict.keys())[90:91]:\n",
    "# for f in list(goodFileDict.keys())[1:100]:\n",
    "for f in fullfs:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj)\n",
    "        if(result != None):\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "#             print(result)\n",
    "#             print('vs')\n",
    "#             print(solution)\n",
    "            print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maDureREva rAjyasya tezAm arDaM pradIyatAm   \n",
      "Analyzing  maDureREva\n",
      "0 :  maDureRa ['maDura'] [{'noun': ['i. sg. m.', 'i. sg. n.']}]\n",
      "0 :  maDu ['maDu'] [{'noun': ['acc. sg. n.', 'nom. sg. n.']}]\n",
      "4 :  reRa ['raR'] [{'verb': ['pft. ac. pl. 2']}]\n",
      "7 :  Eva [''] [{'verb': ['impft. [2] ac. du. 1']}]\n",
      "7 :  eva ['eva'] [{'indeclinable': ['prep.']}]\n",
      "Analyzing  rAjyasya\n",
      "0 :  rAjyasya ['rAjya', 'rAj_1', 'rAj_1'] [{'verbform': ['\"SKTMW217.html#H_raajya\"'], 'noun': ['g. sg. n.', 'g. sg. m.'], 'verb': [['ca. pfp. [1]']]}, {'verbform': ['\"SKTMW217.html#H_raaj#1\"'], 'verb': ['pfp. [1]', ['ca. pfp. [1]']]}, {'verbform': ['\"SKTMW217.html#H_raaj#1\"'], 'noun': ['g. sg. n.', 'g. sg. m.'], 'verb': [['ca. pfp. [1]']]}]\n",
      "0 :  rAji ['rAj_2'] [{'noun': ['loc. sg. m.', 'acc. pl. n.', 'nom. pl. n.', 'loc. sg. n.', 'loc. sg. f.']}]\n",
      "0 :  rAjI ['rAj', 'rAj_2'] [{'noun': ['acc. du. f.', 'nom. du. f.', 'nom. sg. f.']}, {'noun': ['acc. du. n.', 'nom. du. n.']}]\n",
      "4 :  asya ['ayam'] [{'noun': ['g. sg. m.', 'g. sg. n.']}]\n",
      "4 :  asya ['as_2'] [{'verb': ['imp. [4] ac. sg. 2']}]\n",
      "Analyzing  tezAm\n",
      "0 :  tezAm ['tad'] [{'noun': ['g. pl. n.', 'g. pl. m.']}]\n",
      "Analyzing  arDam\n",
      "0 :  arDam ['arDa'] [{'noun': ['acc. sg. m.', 'acc. sg. n.', 'nom. sg. n.']}]\n",
      "Analyzing  pradIyatAm\n",
      "0 :  pra ['pra'] []\n",
      "3 :  dIyatAm ['dA_1', 'dA_2', 'dA_3'] [{'verb': ['imp. ps. sg. 3']}, {'verb': ['imp. ps. sg. 3']}, {'verb': ['imp. ps. sg. 3']}]\n",
      "3 :  dIya ['dA_3'] [{'indeclinable': ['abs.']}]\n",
      "7 :  tAm ['tad'] [{'noun': ['acc. sg. f.']}]\n"
     ]
    }
   ],
   "source": [
    "SeeSentence(sentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maDureREva rAjyasya tezAm arDaM pradIyatAm   \n",
      "[['madhura', 'eva'], ['rājya'], ['tad'], ['ardha'], ['pradā']]\n",
      "Lemmas: ['maDura', 'eva', 'rAjya', 'tad', 'arDa', 'pradA']\n",
      "[['91', '2'], ['151'], ['159'], ['31'], ['-263']]\n"
     ]
    }
   ],
   "source": [
    "SeeDCS(dcsObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'327359.p'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(goodFileDict.keys())[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['179084.p',\n",
       " '212470.p',\n",
       " '141314.p',\n",
       " '312382.p',\n",
       " '371565.p',\n",
       " '20967.p',\n",
       " '178347.p',\n",
       " '289080.p',\n",
       " '334071.p',\n",
       " '407484.p',\n",
       " '209444.p']"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7941\n",
    "# Results: \n",
    "# Mean:  65.7963242743\n",
    "# Percentiles:  [   5.88   50.     66.67   85.71  100.  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
