{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from AlgoTestFactory import *\n",
    "\n",
    "# altf1 = AlgoTestFactory([0, 10000], 15, savePath=\"Combined_4_test2\", storeAccuracies=True)\n",
    "\n",
    "# altf1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader Started[Prob]...\n",
      "Dataloader Finished[Prob]...\n"
     ]
    }
   ],
   "source": [
    "from SktWsegRWR_utf8 import *\n",
    "import pickle\n",
    "import ProbData\n",
    "from ProbModels import *\n",
    "import multiprocessing\n",
    "import math\n",
    "import json\n",
    "import pprint\n",
    "import csv\n",
    "from utilities import *\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "loaded_SKT = pickle.load(open('../Simultaneous_CompatSKT_10K.p', 'rb'))\n",
    "loaded_DCS = pickle.load(open('../Simultaneous_DCS_10K.p', 'rb'))\n",
    "\n",
    "algo = SktWsegRWR(\n",
    "            w2w_modelFunc = pb.get_w2w_mat, \n",
    "            t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "            v2c_modelFunc = pb.get_v2c_ranking,\n",
    "            LMVBLM_pathfinder = pb.LMVBLM_pathfinder,\n",
    "            sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "            partition=[0.25, 0.25, 0.25, 0.1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# goodFileDict = {}\n",
    "# new_flist = os.listdir('../TextSegmentation/CompatSKT/')\n",
    "# for f in new_flist:\n",
    "#     goodFileDict[f] = '../TextSegmentation/CompatSKT/' + f\n",
    "# pickle.dump(goodFileDict, open('mergedGood_CompatSKT.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100078"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_pf1 = pd.read_csv('extras/pvbnhi@pf.csv', header=None, names=['file', 'miss', 'miss2'])\n",
    "# df_pf2 = pd.read_csv('extras/pvbnhi@skt.csv', header=None, names=['file', 'miss', 'miss2'])\n",
    "# df_pf3 = pd.read_csv('extras/pvbnhi@upd.csv', header=None, names=['file', 'miss', 'miss2'])\n",
    "\n",
    "# df_pf1['miss'] = df_pf1[df_pf1['miss'] != 'Incomplete chunk']['miss'].astype(int)\n",
    "# df_pf1 = df_pf1[df_pf1['miss'] == 0]\n",
    "# df_pf1['folder'] = '../TextSegmentation/Pickle_Files/'\n",
    "\n",
    "# df_pf2['miss'] = df_pf2[df_pf2['miss'] != 'Incomplete chunk']['miss'].astype(int)\n",
    "# df_pf2 = df_pf2[df_pf2['miss'] == 0]\n",
    "# df_pf2['folder'] = '../TextSegmentation/corrected_10to20/'\n",
    "\n",
    "# df_pf3['miss'] = df_pf3[df_pf3['miss'] != 'Incomplete chunk']['miss'].astype(int)\n",
    "# df_pf3 = df_pf3[df_pf3['miss'] == 0]\n",
    "# df_pf3['folder'] = '../TextSegmentation/Updated Pickles/'\n",
    "\n",
    "# frames = [df_pf1, df_pf2, df_pf3]\n",
    "# df_pf = pd.concat(frames)\n",
    "# %reset_selective df_pf1\n",
    "# %reset_selective df_pf2\n",
    "# %reset_selective df_pf3\n",
    "# goodFileDict = {}\n",
    "# for index, row in df_pf.iterrows():\n",
    "#     goodFileDict['%d.p' % row['file']] = '%s%d.p' % (row['folder'], row['file'])\n",
    "len(goodFileDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49441"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo.partition = np.array([0.33,0.33,0.33,0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31031.p2 \t 66.66666666666667\n"
     ]
    }
   ],
   "source": [
    "fs = ['31031.p2']\n",
    "np.set_printoptions(precision=4)\n",
    "# for f in list(goodFileDict.keys())[1:20]:\n",
    "# for f in list(goodFileDict.keys())[1:100]:\n",
    "for f in fs:\n",
    "#     print('=='*20)\n",
    "    sentenceObj, dcsObj = loadSentence_nopre(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj, verbose = False, supervised=True, eta=0.1)\n",
    "        if(result != None):\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadSentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-8e34165bc39f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'30240.p'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(goodFileDict[f])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'../TextSegmentation/Updated Pickles/30240.p'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mSeeSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mSeeDCS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loadSentence' is not defined"
     ]
    }
   ],
   "source": [
    "f = '30240.p'\n",
    "# print(goodFileDict[f])\n",
    "s, d = loadSentence(f, '../TextSegmentation/Updated Pickles/30240.p')\n",
    "SeeSentence(s)\n",
    "SeeDCS(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "partitions = [\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.45, 0.05, 0.25, 0.25],\n",
    "    [0.25, 0.45, 0.25, 0.05],\n",
    "    [0.25, 0.05, 0.45, 0.25],\n",
    "    [0.25, 0.05, 0.25, 0.45],\n",
    "    [0,0,0,0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319234.p2 \t 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tatra', 'daRqa', 'mahant', 'dEva', 'dAruRa', 'kf', 'pat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "319234.p2 \t 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tatra', 'daRqa', 'mahant', 'kf', 'dAruRa', 'dEva', 'pat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "319234.p2 \t 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tatra', 'daRqa', 'kf', 'mahant', 'dAruRa', 'dEva', 'pat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "319234.p2 \t 100.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tatra', 'daRqa', 'mahant', 'dAruRa', 'dEva', 'kf', 'pat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "319234.p2 \t 85.71428571428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tatra', 'daRqa', 'mahant', 'dEva', 'dAruRa', 'kft', 'pat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "319234.p2 \t 57.142857142857146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tatra', 'daRqa', 'dAru', 'kft', 'mahant', 'dava', 'pat']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n"
     ]
    }
   ],
   "source": [
    "def debugSentences(fs, partition):\n",
    "    np.set_printoptions(precision=4)\n",
    "    # for f in list(goodFileDict.keys())[1:20]:\n",
    "    # for f in list(goodFileDict.keys())[1:100]:\n",
    "    for f in fs:\n",
    "    #     print('=='*20)\n",
    "        sentenceObj = loaded_SKT[f]\n",
    "        dcsObj = loaded_DCS[f]\n",
    "        solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "        solution_no_pvb = [removePrefix(l) for l in solution]\n",
    "#         print('='*40)\n",
    "#         print(dcsObj.lemmas)\n",
    "#         print(solution)\n",
    "\n",
    "#         SeeSentence(sentenceObj)\n",
    "        if(sentenceObj != None):\n",
    "            algo.partition = np.array(partition)\n",
    "            result, detail = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "            if(result != None):\n",
    "                solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "                ac = Accuracy(result, dcsObj)\n",
    "                print(f, \"\\t\", ac)\n",
    "#                 display(detail['sentence'])\n",
    "#                 display(detail['nodeList'])\n",
    "#                 display(detail['DCSLemmas'])\n",
    "                \n",
    "                display(result)\n",
    "#                 print(detail['nodeList'])\n",
    "#                 print('Initial Query:', detail['initialQuery'])\n",
    "#                 for step in range(detail['steps']):\n",
    "#                     print('-'*30)\n",
    "#                     print('Step:', step)\n",
    "#                     print('-'*30)\n",
    "#                     print('Winner:', detail[str(step)]['winner'])\n",
    "#                     print('Removed:', detail[str(step)]['removed'])\n",
    "#                     print('Query:', detail[str(step)]['updated_query'])\n",
    "#                     print(detail[str(step)]['w2w_samecng_score'])\n",
    "        print('='*30)\n",
    "\n",
    "fs = [list(loaded_SKT.keys())[30]]\n",
    "debugSentences(fs, partitions[0])\n",
    "debugSentences(fs, partitions[1])\n",
    "debugSentences(fs, partitions[2])\n",
    "debugSentences(fs, partitions[3])\n",
    "debugSentences(fs, partitions[4])\n",
    "debugSentences(fs, partitions[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty name in file 7302\n"
     ]
    }
   ],
   "source": [
    "algo.partition = np.array([ 0.25,  0.05,  0.45,   0.25])\n",
    "\n",
    "# algo.partition = np.random.random(size=(4,))\n",
    "# algo.partition = np.array(defaultPartition)\n",
    "algo.partition /= np.sum(algo.partition)\n",
    "\n",
    "with open('.temp/partition_datas_04_probFixed.csv', 'w') as wcsv_fh:\n",
    "    wcsv = csv.writer(wcsv_fh)\n",
    "    for f in list(loaded_SKT.keys())[0:2000]:\n",
    "    # for f in fullfs:\n",
    "        sentenceObj = loaded_SKT[f]\n",
    "        dcsObj = loaded_DCS[f]\n",
    "        if(sentenceObj != None):\n",
    "#             if any(algo.partition[:-1:] < 0.05) or any(algo.partition[:-1:] > 0.95):\n",
    "#                 wcsv.writerow(algo.partition)\n",
    "# #                 algo.partition = np.random.random(size=(4,))\n",
    "#                 algo.partition = np.array(defaultPartition)\n",
    "#                 algo.partition /= np.sum(algo.partition)\n",
    "            result = algo.predict(sentenceObj, dcsObj, supervised=True, eta = 0.1, weightCollectorCSV = wcsv)\n",
    "            if(result != None):\n",
    "                ac = Accuracy(result, dcsObj)\n",
    "                solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "#                 print(result)\n",
    "#                 print('vs')\n",
    "#                 print(solution)\n",
    "\n",
    "#                 print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32  0.33  0.32  0.  ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.33,  0.34,  0.33,  0.  ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(algo.partition)\n",
    "algo.partition/np.sum(algo.partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fullfs = ['105587.p','293473.p','379245.p']\n",
    "fullfs = ['302864.p', '292204.p', '161425.p', '128533.p', '265112.p', '16349.p', '320178.p', '334655.p', '331468.p', '365975.p', '434538.p', '148267.p', '340997.p', '204751.p', '289589.p', '423330.p', '276728.p', '105056.p', '325962.p', '383515.p', '60055.p', '228316.p', '192549.p', '169215.p', '393452.p', '433996.p', '440103.p', '68686.p', '157189.p', '440567.p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadSentence' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4bbaad956bd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m#=================================================================\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m \u001b[0mGetSomeJSON\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-4bbaad956bd0>\u001b[0m in \u001b[0;36mGetSomeJSON\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     print(len(fullfs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfullfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodFileDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceObj\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunDetails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loadSentence' is not defined"
     ]
    }
   ],
   "source": [
    "fullfs = ['302864.p', '292204.p', '161425.p', '128533.p', '265112.p', '16349.p', '320178.p', '334655.p', '331468.p', '365975.p', '434538.p', '148267.p', '340997.p', '204751.p', '289589.p', '423330.p', '276728.p', '105056.p', '325962.p', '383515.p', '60055.p', '228316.p', '192549.p', '169215.p', '393452.p', '433996.p', '440103.p', '68686.p', '157189.p', '440567.p']\n",
    "def GetSomeJSON():\n",
    "    lowScore = []\n",
    "    midScore = []\n",
    "    highScore = []\n",
    "    np.set_printoptions(precision=4)\n",
    "#     for i in range(1, 400):\n",
    "#         f = list(goodFileDict.keys())[i]\n",
    "#     print(len(fullfs))\n",
    "    for f in fullfs:\n",
    "        sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "        if(sentenceObj != None):\n",
    "            result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "\n",
    "            if(result != None):\n",
    "                runDetails['file'] = f\n",
    "                ac = runDetails['accuracy']\n",
    "#                 print(f, ac)\n",
    "\n",
    "                # CODE FOR SELECTING FILES \n",
    "#                 if(i%100 == 0):\n",
    "#                     print('Chekpoint:', i)\n",
    "                if(ac <= 40):\n",
    "                    lowScore.append(runDetails)\n",
    "                elif (ac <= 60):\n",
    "                    if(ac >= 45):\n",
    "                        midScore.append(runDetails)\n",
    "                elif (ac <= 100):\n",
    "                    if(ac >= 80):\n",
    "                        highScore.append(runDetails)\n",
    "\n",
    "    print('Lowscore files found:', len(lowScore))\n",
    "    print('Midscore files found:', len(midScore))\n",
    "    print('Highscore files found:', len(highScore))\n",
    "\n",
    "    lowScore = lowScore[0:10]\n",
    "    midScore = midScore[0:10]\n",
    "    highScore = highScore[0:10]\n",
    "    pickle.dump(lowScore, open('lowScore.p', 'wb'))\n",
    "    pickle.dump(midScore, open('midScore.p', 'wb'))\n",
    "    pickle.dump(highScore, open('highScore.p', 'wb'))\n",
    "\n",
    "#=================================================================\n",
    "GetSomeJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chekpoint: 400\n",
      "Empty name in file 240430\n",
      "Chekpoint: 1200\n",
      "Chekpoint: 1600\n",
      "Chekpoint: 2000\n",
      "Chekpoint: 2800\n",
      "Chekpoint: 3200\n",
      "Chekpoint: 3600\n",
      "Chekpoint: 4000\n",
      "Empty name in file 131042\n",
      "Chekpoint: 4400\n",
      "Chekpoint: 4800\n",
      "Empty name in file 431033\n",
      "Chekpoint: 5200\n",
      "Empty name in file 32130\n",
      "Chekpoint: 5600\n",
      "Chekpoint: 6000\n",
      "Chekpoint: 6400\n",
      "Chekpoint: 6800\n",
      "Empty name in file 190965\n",
      "Chekpoint: 7200\n",
      "Chekpoint: 7600\n",
      "Empty name in file 19229\n",
      "Chekpoint: 8000\n",
      "Empty name in file 310144\n",
      "Empty name in file 156107\n",
      "Empty name in file 389091\n",
      "Empty name in file 7302\n",
      "Chekpoint: 8800\n",
      "Empty name in file 333881\n",
      "Chekpoint: 9200\n",
      "Empty name in file 32452\n",
      "Chekpoint: 9600\n",
      "Chekpoint: 10000\n"
     ]
    }
   ],
   "source": [
    "def MacroAccuracy():\n",
    "    allAcs = []\n",
    "    np.set_printoptions(precision=4)\n",
    "    algo.partition = np.array([ 0.05,  0.05,  0.45,   0.45])\n",
    "    i = 0\n",
    "    for f in loaded_SKT.keys():\n",
    "        i += 1\n",
    "    # for f in fullfs:\n",
    "        sentenceObj = loaded_SKT[f]\n",
    "        dcsObj = loaded_DCS[f]\n",
    "        if(sentenceObj != None):\n",
    "            result = algo.predict(sentenceObj, dcsObj, verbose = False)\n",
    "            \n",
    "            if(result != None):\n",
    "#                 print(result)\n",
    "#                 print(dcsObj.lemmas)\n",
    "                ac = Accuracy(result, dcsObj)\n",
    "                allAcs.append(ac)\n",
    "#                 print(f, ac)\n",
    "\n",
    "                # CODE FOR SELECTING FILES \n",
    "                if(i%400 == 0):\n",
    "                    print('Chekpoint:', i)\n",
    "#                 if i >= 2000:\n",
    "#                     break\n",
    "    allAcs = np.array(allAcs)\n",
    "    return allAcs\n",
    "\n",
    "\n",
    "#=================================================================\n",
    "allAcs = MacroAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: [ 0.15  0.05  0.45  0.45]\n",
      "8756\n",
      "76.5010499609\n",
      "Min: 0.000000, Max: 100.000000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEZCAYAAAC99aPhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4UjkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c9a3a5a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Accuracy %: 18.3645500228\n"
     ]
    }
   ],
   "source": [
    "print('Partition:', algo.partition)\n",
    "print(len(allAcs))\n",
    "print(np.mean(allAcs))\n",
    "print('Min: %f, Max: %f' % (np.min(allAcs), np.max(allAcs)))\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(allAcs, 4, normed=False)\n",
    "plt.xlabel('MicroAccuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of MicroAccuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print('Macro Accuracy %:', 100*np.sum(allAcs >= 95)/allAcs.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SeeSomeJSON(region = 'mid', files = ['lowScore.p', 'midScore.p', 'highScore.p']):\n",
    "    np.set_printoptions(precision=3)\n",
    "    if region == 'low':\n",
    "        p = pickleFixLoad(files[0])\n",
    "    elif region == 'mid':\n",
    "        p = pickleFixLoad(files[1])\n",
    "    else:\n",
    "        p = pickleFixLoad(files[2])\n",
    "#     for pf in p:\n",
    "#         print(pf['file'])\n",
    "    n_steps = p[0]['steps']\n",
    "    for s in range(n_steps):\n",
    "        \n",
    "        print('Step:', s)\n",
    "        print('='*20)\n",
    "        \n",
    "        for key, val in p[0][str(s)].items():\n",
    "            print(key, \":\")\n",
    "            print(val)\n",
    "            print('-'*20)\n",
    "        \n",
    "SeeSomeJSON('low')\n",
    "print('='*20)\n",
    "SeeSomeJSON('mid')\n",
    "print('='*20)\n",
    "SeeSomeJSON('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "35 weird predictions encountered.\n"
     ]
    }
   ],
   "source": [
    "def ArePredictionsOK():\n",
    "    with open('.temp/weird.csv', 'w') as fh:\n",
    "        wcsv = csv.writer(fh)\n",
    "        wcsv.writerow(['filename', 'sentence', 'solution', 'prediction'])\n",
    "        np.set_printoptions(precision=4)\n",
    "        badCount = 0\n",
    "        for i in range(1, 600):\n",
    "            f = list(goodFileDict.keys())[i]\n",
    "\n",
    "            sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "            if(sentenceObj != None):\n",
    "                result = algo.predict(sentenceObj, dcsObj, verbose = False)\n",
    "                if(result != None):            \n",
    "                    solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "                    ac = Accuracy(result, dcsObj)\n",
    "                    if ac >= 100 and len(result) != len(solution):\n",
    "                        badCount += 1\n",
    "                        if(badCount%10 == 0):\n",
    "                            print(\"=\"*40)\n",
    "                        sline = [f, sentenceObj.sentence, solution, result]\n",
    "                        wcsv.writerow(sline)\n",
    "        print(badCount, 'weird predictions encountered.')\n",
    "        \n",
    "ArePredictionsOK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKT ANALYZE\n",
      "---------------\n",
      "paYca ratnAni muKyAni coparatnacatuzwayam   \n",
      "Analyzing: paYca\n",
      "-------------------------\n",
      "Analyzing: ratnAni\n",
      "0 : ratnAni [0, 'ratna', 81] [1, 'ratna', 41] \n",
      "0 : ratnAni [2, 'ratna', 61] \n",
      "-------------------------\n",
      "Analyzing: muKyAni\n",
      "0 : muKyAni [3, 'muKya', 81] [4, 'muKya', 41] \n",
      "0 : muKyAni [5, 'muKya', 61] \n",
      "-------------------------\n",
      "Analyzing: coparatnacatuzwayam\n",
      "0 : ca [6, 'ca', 2] \n",
      "9 : catuzwayam [7, 'catuzwaya', 31] [8, 'catuzwaya', 69] [9, 'catuzwaya', 71] \n",
      "4 : ratna [10, 'ratna', 3] \n",
      "1 : uparatna [11, 'uparatna', 3] \n",
      "1 : Upa [12, 'vap', -158] \n",
      "-------------------------\n",
      "Analyzing  paYca\n",
      "0 :  paYca [] []\n",
      "Analyzing  ratnAni\n",
      "0 :  ratnAni ['ratna'] [{'noun': ['acc. pl. n.', 'nom. pl. n.']}]\n",
      "0 :  ratnAni ['ratna'] [{'noun': ['voc. pl. n.']}]\n",
      "Analyzing  muKyAni\n",
      "0 :  muKyAni ['muKya'] [{'noun': ['acc. pl. n.', 'nom. pl. n.']}]\n",
      "0 :  muKyAni ['muKya'] [{'noun': ['voc. pl. n.']}]\n",
      "Analyzing  coparatnacatuzwayam\n",
      "0 :  ca ['ca'] [{'indeclinable': ['conj.']}]\n",
      "9 :  catuzwayam ['catuzwaya'] [{'noun': ['acc. sg. m.', 'acc. sg. n.', 'nom. sg. n.']}]\n",
      "4 :  ratna ['ratna'] [{'compound': ['iic.']}]\n",
      "1 :  uparatna ['uparatna'] [{'compound': ['iic.']}]\n",
      "1 :  Upa ['vap', 'vap'] [{'verb': ['pft. ac. pl. 2']}, {'verb': ['pft. ac. pl. 2']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceObj, dcsObj = loadSentence('1.p', '../TextSegmentation/corrected_10to20/1.p')\n",
    "SeeSentence(sentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCS ANALYZE\n",
      "---------------\n",
      "upacAreRa SIlena rUpayOvanasaMpadA   \n",
      "[['upacāra'], ['śīla'], ['rūpa', 'yauvana', 'sampad']]\n",
      "Lemmas: ['upacAra', 'SIla', 'rUpa', 'yOvana', 'sampad']\n",
      "[['89'], ['91'], ['3', '3', '90']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SeeDCS(dcsObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CSVforSupervised():\n",
    "    np.set_printoptions(precision=4)\n",
    "    # Clean the csv files\n",
    "    metPerfFH = open('.temp/metPerfFH.csv', 'w')\n",
    "    metPerfFH_bin = open('.temp/metPerfFH_bin.csv', 'w')\n",
    "\n",
    "    metPerfFH.write('w2w,t2t,w2w_samecng,InDCS\\n')\n",
    "    metPerfFH_bin.write('w2w,t2t,w2w_samecng,InDCS\\n')\n",
    "\n",
    "    metPerfFH.close()\n",
    "    metPerfFH_bin.close()\n",
    "    ######################\n",
    "    gfl = list(goodFileDict.keys())\n",
    "    for i in range(0, 11000):\n",
    "        f = gfl[i]\n",
    "        if(i%250 == 0):\n",
    "            print('Checkpoint:', i)\n",
    "        sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "        \n",
    "        if(sentenceObj != None):\n",
    "            result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "jsonBatch = []\n",
    "for f_ in lowScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "pickle.dump(jsonBatch, open('.temp/lowScore.p','wb'))\n",
    "print('33 % Complete')\n",
    "#################################################################\n",
    "jsonBatch = []\n",
    "for f_ in midScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "pickle.dump(jsonBatch, open('.temp/midScore.p','wb'))\n",
    "print('67 % Complete')\n",
    "#################################################################\n",
    "jsonBatch = []\n",
    "for f_ in highScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "print(pprint.pprint(jsonBatch))\n",
    "pickle.dump(jsonBatch, open('.temp/highScore.p','wb'))\n",
    "print('100 % Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline_SKTs = pickle.load(open('../Simult_baselineSKT.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't form query node in 1076 files\n"
     ]
    }
   ],
   "source": [
    "def DownloadBaselineOutput():\n",
    "    pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "    algo = SktWsegRWR(\n",
    "                w2w_modelFunc = pb.get_w2w_mat, \n",
    "                t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "                v2c_modelFunc = pb.get_v2c_ranking,\n",
    "                sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "                partition=[0.25, 0.25, 0.25, 0.1]\n",
    "            )\n",
    "    \n",
    "    counter = 0\n",
    "    no_query = 0\n",
    "    with open('baseline_outputs_post.csv', 'w') as fh:\n",
    "        bcsv = csv.writer(fh)\n",
    "        bcsv.writerow(['filename', 'lemma', 'name', 'cng', 'pos', 'source'])\n",
    "        for f in baseline_SKTs.keys():\n",
    "            counter += 1\n",
    "#             if counter % 200 == 0:\n",
    "#                 print('chekpoint', counter)\n",
    "#                 if counter > 20:\n",
    "#                     break\n",
    "\n",
    "            skt = baseline_SKTs[f]\n",
    "            if skt != None:\n",
    "                result, runDetails = algo.predict(skt, None, verbose = True)\n",
    "                if result == None:\n",
    "                    no_query += 1\n",
    "#                     SeeSentence(skt)\n",
    "                    continue\n",
    "                (chunkDict, lemmaList, wordList, revMap2Chunk, qu, cngList, verbs, tuplesMain) = SentencePreprocess(skt)\n",
    "    #             print(runDetails.keys())\n",
    "    #             SeeSentence(skt)\n",
    "    #             display(runDetails['nodeList'])\n",
    "    #             print('STEPS:', int(runDetails['steps']))\n",
    "    #             print(eval(runDetails['initialQuery']))\n",
    "                for qi in eval(runDetails['initialQuery']):\n",
    "                    cid, pos, tid = revMap2Chunk[int(qi)]\n",
    "    #                 print([f, lemmaList[qi], wordList[qi], cngList[qi], pos, 'initial_query'])\n",
    "                    bcsv.writerow([f, lemmaList[qi], wordList[qi], cngList[qi], pos, 'initial_query'])\n",
    "                for step in range(int(runDetails['steps'])):\n",
    "                    wt = runDetails[str(step)]['winner']\n",
    "                    cid, pos, tid = revMap2Chunk[wt[0]]\n",
    "    #                 print([f, wt[2], wt[1], wt[3], pos, 'winner'])\n",
    "                    bcsv.writerow([f, wt[2], wt[1], wt[3], pos, 'winner'])\n",
    "            else:\n",
    "                no_query += 1\n",
    "\n",
    "    print('Can\\'t form query node in', no_query, 'files')\n",
    "DownloadBaselineOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chekpoint 400\n",
      "chekpoint 800\n",
      "chekpoint 1200\n",
      "Empty name in file 7302\n",
      "chekpoint 1600\n",
      "chekpoint 2000\n",
      "Can't form query node in 255 files\n"
     ]
    }
   ],
   "source": [
    "def GetLogReg_TrainData():\n",
    "    algo.partition = np.array([ 0.25,  0.05,  0.4,   0.25])    \n",
    "    counter = 0\n",
    "    no_query = 0\n",
    "    with open('logReg_train_full.csv', 'w') as fh:\n",
    "        bcsv = csv.writer(fh)\n",
    "        bcsv.writerow(['w2w', 't2t', 'scng', 'DSCLemma'])\n",
    "        for f in loaded_SKT.keys():\n",
    "            counter += 1\n",
    "            if counter % 400 == 0:\n",
    "                print('chekpoint', counter)\n",
    "                if counter >= 2000:\n",
    "                    break\n",
    "\n",
    "            skt = loaded_SKT[f]\n",
    "            dcs = loaded_DCS[f]\n",
    "            if skt != None:\n",
    "                result, runDetails = algo.predict(skt, dcs, verbose = True)\n",
    "                if result == None:\n",
    "                    no_query += 1\n",
    "#                     SeeSentence(skt)\n",
    "                    continue\n",
    "                (chunkDict, lemmaList, wordList, revMap2Chunk, qu, cngList, verbs, tuplesMain) = SentencePreprocess(skt)\n",
    "                sol, solNoPvb = GetSolutions(dcs)\n",
    "#                 print(runDetails.keys())\n",
    "# #                 SeeSentence(skt)\n",
    "#                 display(runDetails['DCSLemmas'])\n",
    "#                 print('STEPS:', int(runDetails['steps']))\n",
    "#                 print(eval(runDetails['initialQuery']))\n",
    "                for step in range(int(runDetails['steps'])):\n",
    "                    stepData = runDetails[str(step)]\n",
    "#                     print(stepData['final_rank'])\n",
    "                    for ri in range(np.where(stepData['winner'][0] == stepData['final_rank'])[0][0], len(stepData['final_rank'])):\n",
    "#                         print(len(stepData['final_rank']))\n",
    "                        w = stepData['final_rank'][ri]\n",
    "#                         print(lemmaList[w] in sol,lemmaList[w] in solNoPvb , lemmaList[w])\n",
    "                        bcsv.writerow([stepData['w2w_score'][0,w], stepData['t2t_score'][0,w], stepData['w2w_samecng_score'][0,w], lemmaList[w] in sol or lemmaList[w] in solNoPvb])\n",
    "            else:\n",
    "                no_query += 1\n",
    "\n",
    "    print('Can\\'t form query node in', no_query, 'files')\n",
    "GetLogReg_TrainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
