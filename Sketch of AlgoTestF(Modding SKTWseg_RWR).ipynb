{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from AlgoTestFactory import *\n",
    "\n",
    "# altf1 = AlgoTestFactory([0, 10000], 15, savePath=\"Combined_4_test2\", storeAccuracies=True)\n",
    "\n",
    "# altf1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader Started[Prob]...\n",
      "Dataloader Finished[Prob]...\n"
     ]
    }
   ],
   "source": [
    "from SktWsegRWR_utf8 import *\n",
    "import pickle\n",
    "import ProbData\n",
    "from ProbModels import *\n",
    "import multiprocessing\n",
    "import math\n",
    "import json\n",
    "import pprint\n",
    "import csv\n",
    "from utilities import *\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "goodFileDict = pickle.load(open('mergedGood_v4.p', 'rb'))\n",
    "algo = SktWsegRWR(\n",
    "            w2w_modelFunc = pb.get_w2w_mat, \n",
    "            t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "            v2c_modelFunc = pb.get_v2c_ranking,\n",
    "            sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "            partition=[0.25, 0.25, 0.25, 0.1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-54beb9ccbbf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# for f in list(goodFileDict.keys())[1:20]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# for f in list(goodFileDict.keys())[1:100]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#     print('=='*20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodFileDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fs' is not defined"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=4)\n",
    "# for f in list(goodFileDict.keys())[1:20]:\n",
    "# for f in list(goodFileDict.keys())[1:100]:\n",
    "for f in fs:\n",
    "#     print('=='*20)\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj, verbose = False)\n",
    "        if(result != None):\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../TextSegmentation/Pickle_Files/306555.p\n",
      "SKT ANALYZE\n",
      "---------------\n",
      "svaDarmaH  svargAyAnantyAya ca   \n",
      "Analyzing: svaDarmaḥ\n",
      "0 : sva [0, 'sva', 3] \n",
      "3 : Darmas [1, 'Darma', 29] \n",
      "-------------------------\n",
      "Analyzing: svargAyAnantyAya\n",
      "0 : svargAya [2, 'svarga', 109] [3, 'svarga', 111] \n",
      "0 : svargAs [4, 'svarga', 80] [5, 'svarga', 40] [6, 'svarga', 39] \n",
      "0 : svarga [7, 'svarga', 3] \n",
      "0 : svargA [8, 'svarga', 30] \n",
      "0 : svar [9, 'svar', 1] \n",
      "0 : sva [10, 'sva', 3] \n",
      "0 : svA [11, 'sva', 30] \n",
      "3 : fk [12, 'fc', 30] \n",
      "3 : fk [13, 'fc', 31] [14, 'fc', 29] [15, 'fc', 71] \n",
      "4 : gAya [16, 'ga', 109] [17, 'ga', 111] \n",
      "4 : gAya [18, 'gA', -32] \n",
      "4 : gAs [19, 'ga', 80] [20, 'ga', 40] [21, 'ga', 39] [22, 'go', 80] [23, 'go', 79] \n",
      "4 : gAs [24, 'gA', -302] \n",
      "4 : ga [25, 'ga', 3] \n",
      "4 : gA [26, 'ga', 30] \n",
      "5 : ayAn [27, 'aya', 79] \n",
      "5 : ayAn [28, 'yA', -49] \n",
      "5 : ayA [29, 'aya', 30] \n",
      "5 : aya [30, 'aya', 3] \n",
      "6 : yAn [31, 'yad', 79] \n",
      "6 : yA [32, 'yad', 30] \n",
      "7 : AnantyAya [33, 'Anantya', 109] [34, 'Anantya', 111] \n",
      "7 : an [35, 'an', 3] \n",
      "9 : antyAya [36, 'antya', 109] [37, 'antya', 111] \n",
      "-------------------------\n",
      "Analyzing: ca\n",
      "0 : ca [38, 'ca', 2] \n",
      "-------------------------\n",
      "Analyzing  svaDarmaḥ\n",
      "0 :  sva ['sva'] [{'compound': ['iic.']}]\n",
      "3 :  Darmas ['Darma'] [{'noun': ['nom. sg. m.']}]\n",
      "Analyzing  svargAyAnantyAya\n",
      "0 :  svargAya ['svarga'] [{'noun': ['dat. sg. m.', 'dat. sg. n.']}]\n",
      "0 :  svargAs ['svarga'] [{'noun': ['nom. pl. m.', 'acc. pl. f.', 'nom. pl. f.']}]\n",
      "0 :  svarga ['svarga'] [{'compound': ['iic.']}]\n",
      "0 :  svargA ['svarga'] [{'noun': ['nom. sg. f.']}]\n",
      "0 :  svar ['svar'] [{'undetermined': ['und.']}]\n",
      "0 :  sva ['sva'] [{'compound': ['iic.']}]\n",
      "0 :  svA ['sva'] [{'noun': ['nom. sg. f.']}]\n",
      "3 :  fk ['fc'] [{'noun': ['nom. sg. f.']}]\n",
      "3 :  fk ['fc'] [{'noun': ['nom. sg. m.', 'acc. sg. n.', 'nom. sg. n.']}]\n",
      "4 :  gAya ['ga'] [{'noun': ['dat. sg. m.', 'dat. sg. n.']}]\n",
      "4 :  gAya ['gA'] [{'verb': ['imp. [1] ac. sg. 2']}]\n",
      "4 :  gAs ['ga', 'go'] [{'noun': ['nom. pl. m.', 'acc. pl. f.', 'nom. pl. f.']}, {'noun': ['acc. pl. m.', 'acc. pl. f.']}]\n",
      "4 :  gAs ['gA'] [{'verb': ['inj. [1] ac. sg. 2']}]\n",
      "4 :  ga ['ga'] [{'compound': ['iic.']}]\n",
      "4 :  gA ['ga'] [{'noun': ['nom. sg. f.']}]\n",
      "5 :  ayAn ['aya'] [{'noun': ['acc. pl. m.']}]\n",
      "5 :  ayAn ['yA'] [{'verb': ['impft. [2] ac. pl. 3']}]\n",
      "5 :  ayA ['aya'] [{'noun': ['nom. sg. f.']}]\n",
      "5 :  aya ['aya'] [{'compound': ['iic.']}]\n",
      "5 :  A ['A'] []\n",
      "6 :  yAn ['yad'] [{'noun': ['acc. pl. m.']}]\n",
      "6 :  yA ['yad'] [{'noun': ['nom. sg. f.']}]\n",
      "7 :  AnantyAya ['Anantya'] [{'noun': ['dat. sg. m.', 'dat. sg. n.']}]\n",
      "7 :  an ['an'] [{'compound': ['iic.']}]\n",
      "9 :  antyAya ['antya'] [{'noun': ['dat. sg. m.', 'dat. sg. n.']}]\n",
      "Analyzing  ca\n",
      "0 :  ca ['ca'] [{'indeclinable': ['conj.']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = '306555.p'\n",
    "print(goodFileDict[f])\n",
    "s, d = loadSentence(f, goodFileDict[f])\n",
    "SeeSentence(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'306555.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-33724163a963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'='\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mdebugSentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-33724163a963>\u001b[0m in \u001b[0;36mdebugSentences\u001b[1;34m(fs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#     print('=='*20)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodFileDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceObj\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdetail\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentenceObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdcsObj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '306555.p'"
     ]
    }
   ],
   "source": [
    "fs = [ '306555.p']\n",
    "def debugSentences(fs):\n",
    "    np.set_printoptions(precision=4)\n",
    "    # for f in list(goodFileDict.keys())[1:20]:\n",
    "    # for f in list(goodFileDict.keys())[1:100]:\n",
    "    for f in fs:\n",
    "    #     print('=='*20)\n",
    "        sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "        if(sentenceObj != None):\n",
    "            result, detail = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "            if(result != None):\n",
    "                solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "                ac = Accuracy(result, dcsObj)\n",
    "                print(f, \"\\t\", ac)\n",
    "                display(detail['sentence'])\n",
    "                display(detail['DCSLemmas'])\n",
    "                display(result)\n",
    "#                 print(detail['nodeList'])\n",
    "                print('Initial Query:', detail['initialQuery'])\n",
    "                for step in range(detail['steps']):\n",
    "                    print('-'*30)\n",
    "                    print('Step:', step)\n",
    "                    print('-'*30)\n",
    "                    print('Winner:', detail[str(step)]['winner'])\n",
    "                    print('Removed:', detail[str(step)]['removed'])\n",
    "                    print('Query:', detail[str(step)]['updated_query'])\n",
    "        print('='*30)\n",
    "\n",
    "debugSentences(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution: ['taTA', 'eva', 'ca', 'kf', 'yaTA', 'sAman', 'eva', 'laB']\n",
      "Solution No Pvb: ['taTA', 'eva', 'ca', 'kf', 'yaTA', 'sAman', 'eva', 'laB']\n",
      "['ca', 'yaTA', 'sAman', 'eva', 'eva', 'taTA', 'kf', 'laB']\n",
      "vs\n",
      "['taTA', 'eva', 'ca', 'kf', 'yaTA', 'sAman', 'eva', 'laB']\n",
      "413967.p \t 100.0\n",
      "Solution: ['vega', 'antara', 'tu', 'anyatama', 'kf', 'karman', 'SItala']\n",
      "Solution No Pvb: ['vega', 'a', 'tu', 'anyatama', 'kf', 'karman', 'SItala']\n",
      "['tu', 'karman', 'SItala', 'vA', 'kf', 'anta', 'j', 'anyatama', 'rA']\n",
      "vs\n",
      "['vega', 'antara', 'tu', 'anyatama', 'kf', 'karman', 'SItala']\n",
      "190134.p \t 71.42857142857143\n",
      "Solution: ['kAla', 'gam', 'tad', 'prasad', 'BU', 'ISvara']\n",
      "Solution No Pvb: ['kAla', 'gam', 'tad', 'sad', 'BU', 'ISvara']\n",
      "['ISvara', 'tad', 'na', 'ka', 'a', 'sad', 'BU', 'gam', 'ala']\n",
      "vs\n",
      "['kAla', 'gam', 'tad', 'prasad', 'BU', 'ISvara']\n",
      "255542.p \t 83.33333333333333\n",
      "Solution: ['buDa', 'BArgava', 'SIGra', 'tadvat', 'pAta', 'yadA', 'sTA']\n",
      "Solution No Pvb: ['buDa', 'BArgava', 'SIGra', 'tadvat', 'pAta', 'yadA', 'sTA']\n",
      "['buDa', 'yadA', 'sTA', 'pA', 'BArgava', 'tadvat', 'ad', 'SIGra', 'yu']\n",
      "vs\n",
      "['buDa', 'BArgava', 'SIGra', 'tadvat', 'pAta', 'yadA', 'sTA']\n",
      "12353.p \t 85.71428571428571\n",
      "Solution: ['sUrya', 'loka', 'vas', 'tAvat', 'yAvat', 'kalpa', 'Sata', 'traya']\n",
      "Solution No Pvb: ['sUrya', 'loka', 'vas', 'tAvat', 'yAvat', 'kalpa', 'Sata', 'traya']\n",
      "['vas', 'kalpa', 'Sata', 'yad', 'tra', 'yad', 'loka', 'a', 'tAvat', 'sUrya', 'av']\n",
      "vs\n",
      "['sUrya', 'loka', 'vas', 'tAvat', 'yAvat', 'kalpa', 'Sata', 'traya']\n",
      "254158.p \t 75.0\n",
      "Solution: ['BU', 'Sru']\n",
      "Solution No Pvb: ['BU', 'Sru']\n",
      "['Sru', 'tu', 'BU']\n",
      "vs\n",
      "['BU', 'Sru']\n",
      "352985.p \t 100.0\n",
      "Solution: ['tad', 'agraja', 'anuSAs', 'arTa', 'yaTAvat', 'puruza', 'fzaBa']\n",
      "Solution No Pvb: ['tad', 'agraja', 'SAs', 'arTa', 'yaTAvat', 'puruza', 'fzaBa']\n",
      "['tad', 'puruza', 'fzaBa', 'arTa', 'yaTA', 'na', 'nu', 'ja', 'agra', 'Szwa', 'av']\n",
      "vs\n",
      "['tad', 'agraja', 'anuSAs', 'arTa', 'yaTAvat', 'puruza', 'fzaBa']\n",
      "71541.p \t 57.142857142857146\n",
      "Solution: ['padma', 'varRa', 'yAna', 'brahman', 'loka', 'prapad']\n",
      "Solution No Pvb: ['padma', 'varRa', 'yAna', 'brahman', 'loka', 'pad']\n",
      "['padma', 'tad', 'pad', 'yad', 'na', 'na', 'na', 'brahman', 'varRa', 'loka']\n",
      "vs\n",
      "['padma', 'varRa', 'yAna', 'brahman', 'loka', 'prapad']\n",
      "107322.p \t 83.33333333333333\n",
      "Solution: ['Srama', 'Keda']\n",
      "Solution No Pvb: ['Srama', 'Keda']\n",
      "['Srama', 'Keda']\n",
      "vs\n",
      "['Srama', 'Keda']\n",
      "78680.p \t 100.0\n",
      "Solution: ['tatas', 'tad', 'paSu', 'utsfj', 'deva', 'yAna', 'gam']\n",
      "Solution No Pvb: ['tatas', 'tad', 'paSu', 'sfj', 'deva', 'yAna', 'gam']\n",
      "['tad', 'paSu', 'yad', 'na', 'tatas', 'na', 'deva', 'jagm', 'vas', 'sfj']\n",
      "vs\n",
      "['tatas', 'tad', 'paSu', 'utsfj', 'deva', 'yAna', 'gam']\n",
      "110997.p \t 71.42857142857143\n",
      "Solution: ['sarva', 'kAma', 'bODa']\n",
      "Solution No Pvb: ['sarva', 'kAma', 'bODa']\n",
      "['sarva', 'ka', 'Ama', 'bODa']\n",
      "vs\n",
      "['sarva', 'kAma', 'bODa']\n",
      "353989.p \t 66.66666666666667\n",
      "Solution: ['dfS', 'arjuna', 'han', 'nAga', 'pat', 'parvata', 'upama']\n",
      "Solution No Pvb: ['dfS', 'arjuna', 'han', 'nAga', 'pat', 'parvata', 'ma']\n",
      "['dfS', 'arjuna', 'parvata', 'upama', 'na', 'han', 'a', 'ga', 'pat']\n",
      "vs\n",
      "['dfS', 'arjuna', 'han', 'nAga', 'pat', 'parvata', 'upama']\n",
      "399224.p \t 85.71428571428571\n",
      "Solution: ['vical', 'alaka', 'lal', 'Anana', 'candra']\n",
      "Solution No Pvb: ['cal', 'alaka', 'lal', 'nana', 'candra']\n",
      "['a', 'candra', 'na', 'ka', 'na', 'dala', 'cal', 'lalta']\n",
      "vs\n",
      "['vical', 'alaka', 'lal', 'Anana', 'candra']\n",
      "365581.p \t 40.0\n",
      "Solution: ['praDAna', 'apsaras', 'paYcan', 'vidyut', 'cal', 'varcas']\n",
      "Solution No Pvb: ['DAna', 'apsaras', 'paYcan', 'dyut', 'cal', 'varcas']\n",
      "['paYcan', 'na', 'praDA', 'api', 'vid', 'cal', 'yuD', 'varcas', 'sarasa']\n",
      "vs\n",
      "['praDAna', 'apsaras', 'paYcan', 'vidyut', 'cal', 'varcas']\n",
      "60458.p \t 50.0\n",
      "Solution: ['bahu', 'doza', 'hara', 'ca', 'eva', 'doza', 'Samana', 'ca', 'tad']\n",
      "Solution No Pvb: ['bahu', 'doza', 'hara', 'ca', 'eva', 'doza', 'Samana', 'ca', 'tad']\n",
      "['hara', 'ca', 'eva', 'ca', 'tad', 'doza', 'bahu', 'doza', 'Samana']\n",
      "vs\n",
      "['bahu', 'doza', 'hara', 'ca', 'eva', 'doza', 'Samana', 'ca', 'tad']\n",
      "186294.p \t 100.0\n",
      "Solution: ['kfzRa', 'arDa', 'aNgula', 'muc', 'taTA', 'arDa', 'arDa', 'apANga']\n",
      "Solution No Pvb: ['kfzRa', 'arDa', 'aNgula', 'muc', 'taTA', 'arDa', 'arDa', 'Nga']\n",
      "['aNgula', 'taTA', 'api', 'arDa', 'arDa', 'gam', 'arDa', 'muc', 'tvad', 'kfzRa', 'ad']\n",
      "vs\n",
      "['kfzRa', 'arDa', 'aNgula', 'muc', 'taTA', 'arDa', 'arDa', 'apANga']\n",
      "257022.p \t 87.5\n",
      "Solution: ['SAstra', 'sarva', 'veda', 'ca', 'dvAdaSan', 'abda', 'ca', 'BU']\n",
      "Solution No Pvb: ['SAstra', 'sarva', 'veda', 'ca', 'dvAdaSan', 'abda', 'ca', 'BU']\n",
      "['ca', 'ca', 'api', 'sarva', 'veda', 'SAstra', 'BU', 'a', 'ad', 'a', 'da', 'dva']\n",
      "vs\n",
      "['SAstra', 'sarva', 'veda', 'ca', 'dvAdaSan', 'abda', 'ca', 'BU']\n",
      "139454.p \t 75.0\n"
     ]
    }
   ],
   "source": [
    "with open('.temp/sandhi_encounters.csv', 'w') as fh:\n",
    "    fcsv = csv.writer(fh)\n",
    "    fcsv.writerow(['left', 'right', 'derivations', 'word_left', 'word_right', 'pos_left', 'pos_right'])\n",
    "np.set_printoptions(precision=6)\n",
    "# for f in list(goodFileDict.keys())[90:91]:\n",
    "for f in list(goodFileDict.keys())[20:40]:\n",
    "# for f in fullfs:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj)\n",
    "        if(result != None):\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "            print(result)\n",
    "            print('vs')\n",
    "            print(solution)\n",
    "            print(f, \"\\t\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fullfs = ['105587.p','293473.p','379245.p']\n",
    "fullfs = ['302864.p', '292204.p', '161425.p', '128533.p', '265112.p', '16349.p', '320178.p', '334655.p', '331468.p', '365975.p', '434538.p', '148267.p', '340997.p', '204751.p', '289589.p', '423330.p', '276728.p', '105056.p', '325962.p', '383515.p', '60055.p', '228316.p', '192549.p', '169215.p', '393452.p', '433996.p', '440103.p', '68686.p', '157189.p', '440567.p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowscore files found: 4\n",
      "Midscore files found: 7\n",
      "Highscore files found: 9\n"
     ]
    }
   ],
   "source": [
    "fullfs = ['302864.p', '292204.p', '161425.p', '128533.p', '265112.p', '16349.p', '320178.p', '334655.p', '331468.p', '365975.p', '434538.p', '148267.p', '340997.p', '204751.p', '289589.p', '423330.p', '276728.p', '105056.p', '325962.p', '383515.p', '60055.p', '228316.p', '192549.p', '169215.p', '393452.p', '433996.p', '440103.p', '68686.p', '157189.p', '440567.p']\n",
    "def GetSomeJSON():\n",
    "    lowScore = []\n",
    "    midScore = []\n",
    "    highScore = []\n",
    "    np.set_printoptions(precision=4)\n",
    "#     for i in range(1, 400):\n",
    "#         f = list(goodFileDict.keys())[i]\n",
    "#     print(len(fullfs))\n",
    "    for f in fullfs:\n",
    "        sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "        if(sentenceObj != None):\n",
    "            result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "\n",
    "            if(result != None):\n",
    "                runDetails['file'] = f\n",
    "                ac = runDetails['accuracy']\n",
    "#                 print(f, ac)\n",
    "\n",
    "                # CODE FOR SELECTING FILES \n",
    "#                 if(i%100 == 0):\n",
    "#                     print('Chekpoint:', i)\n",
    "                if(ac <= 40):\n",
    "                    lowScore.append(runDetails)\n",
    "                elif (ac <= 60):\n",
    "                    if(ac >= 45):\n",
    "                        midScore.append(runDetails)\n",
    "                elif (ac <= 100):\n",
    "                    if(ac >= 80):\n",
    "                        highScore.append(runDetails)\n",
    "\n",
    "    print('Lowscore files found:', len(lowScore))\n",
    "    print('Midscore files found:', len(midScore))\n",
    "    print('Highscore files found:', len(highScore))\n",
    "\n",
    "    lowScore = lowScore[0:10]\n",
    "    midScore = midScore[0:10]\n",
    "    highScore = highScore[0:10]\n",
    "    pickle.dump(lowScore, open('lowScore.p', 'wb'))\n",
    "    pickle.dump(midScore, open('midScore.p', 'wb'))\n",
    "    pickle.dump(highScore, open('highScore.p', 'wb'))\n",
    "\n",
    "#=================================================================\n",
    "GetSomeJSON()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chekpoint: 0\n",
      "Chekpoint: 200\n",
      "Chekpoint: 300\n",
      "Chekpoint: 400\n",
      "Chekpoint: 600\n",
      "Chekpoint: 700\n",
      "Chekpoint: 800\n",
      "Chekpoint: 900\n"
     ]
    }
   ],
   "source": [
    "def MacroAccuracy():\n",
    "    allAcs = []\n",
    "    np.set_printoptions(precision=4)\n",
    "    gfs = list(goodFileDict.keys())\n",
    "    for i in range(1000):\n",
    "#     for i in range(10):\n",
    "        f = gfs[i]\n",
    "        sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "        if(sentenceObj != None):\n",
    "            result = algo.predict(sentenceObj, dcsObj, verbose = False)\n",
    "\n",
    "            if(result != None):\n",
    "                ac = Accuracy(result, dcsObj)\n",
    "                allAcs.append(ac)\n",
    "\n",
    "                # CODE FOR SELECTING FILES \n",
    "                if(i%100 == 0):\n",
    "                    print('Chekpoint:', i)\n",
    "    allAcs = np.array(allAcs)\n",
    "    return allAcs\n",
    "\n",
    "\n",
    "#=================================================================\n",
    "allAcs = MacroAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro Accuracy %: 5.78703703704\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(allAcs, 40, normed=False)\n",
    "\n",
    "plt.xlabel('MicroAccuracy')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of MicroAccuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print('Macro Accuracy %:', 100*np.sum(n[(bins[::] > 95)[:-1:]])/np.sum(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SeeSomeJSON(region = 'mid', files = ['lowScore.p', 'midScore.p', 'highScore.p']):\n",
    "    np.set_printoptions(precision=3)\n",
    "    if region == 'low':\n",
    "        p = pickleFixLoad(files[0])\n",
    "    elif region == 'mid':\n",
    "        p = pickleFixLoad(files[1])\n",
    "    else:\n",
    "        p = pickleFixLoad(files[2])\n",
    "#     for pf in p:\n",
    "#         print(pf['file'])\n",
    "    n_steps = p[0]['steps']\n",
    "    for s in range(n_steps):\n",
    "        \n",
    "        print('Step:', s)\n",
    "        print('='*20)\n",
    "        \n",
    "        for key, val in p[0][str(s)].items():\n",
    "            print(key, \":\")\n",
    "            print(val)\n",
    "            print('-'*20)\n",
    "        \n",
    "SeeSomeJSON('low')\n",
    "print('='*20)\n",
    "SeeSomeJSON('mid')\n",
    "print('='*20)\n",
    "SeeSomeJSON('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "========================================\n",
      "========================================\n",
      "35 weird predictions encountered.\n"
     ]
    }
   ],
   "source": [
    "def ArePredictionsOK():\n",
    "    with open('.temp/weird.csv', 'w') as fh:\n",
    "        wcsv = csv.writer(fh)\n",
    "        wcsv.writerow(['filename', 'sentence', 'solution', 'prediction'])\n",
    "        np.set_printoptions(precision=4)\n",
    "        badCount = 0\n",
    "        for i in range(1, 600):\n",
    "            f = list(goodFileDict.keys())[i]\n",
    "\n",
    "            sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "            if(sentenceObj != None):\n",
    "                result = algo.predict(sentenceObj, dcsObj, verbose = False)\n",
    "                if(result != None):            \n",
    "                    solution = [rom_slp(c) for arr in dcsObj.lemmas for c in arr]\n",
    "                    ac = Accuracy(result, dcsObj)\n",
    "                    if ac >= 100 and len(result) != len(solution):\n",
    "                        badCount += 1\n",
    "                        if(badCount%10 == 0):\n",
    "                            print(\"=\"*40)\n",
    "                        sline = [f, sentenceObj.sentence, solution, result]\n",
    "                        wcsv.writerow(sline)\n",
    "        print(badCount, 'weird predictions encountered.')\n",
    "        \n",
    "ArePredictionsOK()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKT ANALYZE\n",
      "---------------\n",
      "paYca ratnAni muKyAni coparatnacatuzwayam   \n",
      "Analyzing: paYca\n",
      "-------------------------\n",
      "Analyzing: ratnAni\n",
      "0 : ratnAni [0, 'ratna', 81] [1, 'ratna', 41] \n",
      "0 : ratnAni [2, 'ratna', 61] \n",
      "-------------------------\n",
      "Analyzing: muKyAni\n",
      "0 : muKyAni [3, 'muKya', 81] [4, 'muKya', 41] \n",
      "0 : muKyAni [5, 'muKya', 61] \n",
      "-------------------------\n",
      "Analyzing: coparatnacatuzwayam\n",
      "0 : ca [6, 'ca', 2] \n",
      "9 : catuzwayam [7, 'catuzwaya', 31] [8, 'catuzwaya', 69] [9, 'catuzwaya', 71] \n",
      "4 : ratna [10, 'ratna', 3] \n",
      "1 : uparatna [11, 'uparatna', 3] \n",
      "1 : Upa [12, 'vap', -158] \n",
      "-------------------------\n",
      "Analyzing  paYca\n",
      "0 :  paYca [] []\n",
      "Analyzing  ratnAni\n",
      "0 :  ratnAni ['ratna'] [{'noun': ['acc. pl. n.', 'nom. pl. n.']}]\n",
      "0 :  ratnAni ['ratna'] [{'noun': ['voc. pl. n.']}]\n",
      "Analyzing  muKyAni\n",
      "0 :  muKyAni ['muKya'] [{'noun': ['acc. pl. n.', 'nom. pl. n.']}]\n",
      "0 :  muKyAni ['muKya'] [{'noun': ['voc. pl. n.']}]\n",
      "Analyzing  coparatnacatuzwayam\n",
      "0 :  ca ['ca'] [{'indeclinable': ['conj.']}]\n",
      "9 :  catuzwayam ['catuzwaya'] [{'noun': ['acc. sg. m.', 'acc. sg. n.', 'nom. sg. n.']}]\n",
      "4 :  ratna ['ratna'] [{'compound': ['iic.']}]\n",
      "1 :  uparatna ['uparatna'] [{'compound': ['iic.']}]\n",
      "1 :  Upa ['vap', 'vap'] [{'verb': ['pft. ac. pl. 2']}, {'verb': ['pft. ac. pl. 2']}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentenceObj, dcsObj = loadSentence('1.p', '../TextSegmentation/corrected_10to20/1.p')\n",
    "SeeSentence(sentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCS ANALYZE\n",
      "---------------\n",
      "upacAreRa SIlena rUpayOvanasaMpadA   \n",
      "[['upacāra'], ['śīla'], ['rūpa', 'yauvana', 'sampad']]\n",
      "Lemmas: ['upacAra', 'SIla', 'rUpa', 'yOvana', 'sampad']\n",
      "[['89'], ['91'], ['3', '3', '90']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SeeDCS(dcsObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def CSVforSupervised():\n",
    "    np.set_printoptions(precision=4)\n",
    "    # Clean the csv files\n",
    "    metPerfFH = open('.temp/metPerfFH.csv', 'w')\n",
    "    metPerfFH_bin = open('.temp/metPerfFH_bin.csv', 'w')\n",
    "\n",
    "    metPerfFH.write('w2w,t2t,w2w_samecng,InDCS\\n')\n",
    "    metPerfFH_bin.write('w2w,t2t,w2w_samecng,InDCS\\n')\n",
    "\n",
    "    metPerfFH.close()\n",
    "    metPerfFH_bin.close()\n",
    "    ######################\n",
    "    gfl = list(goodFileDict.keys())\n",
    "    for i in range(0, 11000):\n",
    "        f = gfl[i]\n",
    "        if(i%250 == 0):\n",
    "            print('Checkpoint:', i)\n",
    "        sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "        \n",
    "        if(sentenceObj != None):\n",
    "            result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=6)\n",
    "jsonBatch = []\n",
    "for f_ in lowScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "pickle.dump(jsonBatch, open('.temp/lowScore.p','wb'))\n",
    "print('33 % Complete')\n",
    "#################################################################\n",
    "jsonBatch = []\n",
    "for f_ in midScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "pickle.dump(jsonBatch, open('.temp/midScore.p','wb'))\n",
    "print('67 % Complete')\n",
    "#################################################################\n",
    "jsonBatch = []\n",
    "for f_ in highScore[0:10]:\n",
    "    f = f_[0]\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result, runDetails = algo.predict(sentenceObj, dcsObj, verbose = True)\n",
    "        runDetails['file'] = f\n",
    "        jsonBatch.append(runDetails)\n",
    "print(pprint.pprint(jsonBatch))\n",
    "pickle.dump(jsonBatch, open('.temp/highScore.p','wb'))\n",
    "print('100 % Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "a[:-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
