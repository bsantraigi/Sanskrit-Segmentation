{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from AlgoTestFactory import *\n",
    "\n",
    "# altf1 = AlgoTestFactory([0, 10000], 15, savePath=\"Combined_4_test2\", storeAccuracies=True)\n",
    "\n",
    "# altf1.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from SktWsegRWR_utf8 import *\n",
    "import pickle\n",
    "import ProbData\n",
    "from ProbModels import *\n",
    "import multiprocessing\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pb = ProbModels(fullCo_oc_mat = ProbData.fullCo_oc_mat, unigram_counts = ProbData.unigram_counts,\n",
    "               cng2cngFullMat = ProbData.cng2cngFullMat, cng2index_dict = ProbData.cng2index_dict,\n",
    "               w2w_samecng_fullmat=ProbData.w2w_samecng_fullmat, samecng_unigram_counts=ProbData.samecng_unigram_counts,\n",
    "               v2c_fullMat = ProbData.v2c_fullMat)\n",
    "\n",
    "goodFileDict = pickle.load(open('mergedGood_v2.p', 'rb'))\n",
    "algo = SktWsegRWR(\n",
    "            w2w_modelFunc = pb.get_w2w_mat, \n",
    "            t2t_modelFunc = pb.get_cng2cng_mat,\n",
    "            v2c_modelFunc = pb.get_v2c_ranking,\n",
    "            sameCng_modelFunc = pb.get_w2w_samecng_mat,\n",
    "            partition=[0.2, 0.5, 0.2, 0.1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loadSentence(fName, folderTag):\n",
    "        # print('File: ', fName)\n",
    "        try:\n",
    "            dcsObj = pickleFixLoad('../Text Segmentation/DCS_pick/' + fName)           \n",
    "            if folderTag == \"C1020\" :\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/corrected_10to20/' + fName)\n",
    "            else:\n",
    "                sentenceObj = pickleFixLoad('../TextSegmentation/Pickle_Files/' + fName)\n",
    "\n",
    "        except (KeyError, EOFError, pickle.UnpicklingError) as e:\n",
    "            return None, None\n",
    "        return(sentenceObj, dcsObj)\n",
    "    \n",
    "def Accuracy(prediction, dcsObj):\n",
    "    solution = [rom_slp(c) for c in dcsObj.dcs_chunks]\n",
    "    ac = 100*sum(list(map(lambda x: x in solution, prediction)))/len(prediction)\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25\n",
      "73\n",
      "20\n",
      "{'midRange': ['414970.p', '318639.p', '433875.p', '217229.p', '211085.p', '273610.p', '128515.p', '110599.p', '120991.p', '427125.p', '18461.p', '198471.p', '133458.p', '63385.p', '387288.p', '350810.p', '299664.p', '135962.p', '185945.p', '390136.p', '185693.p', '18178.p', '317986.p', '230374.p', '122594.p', '276850.p', '397641.p', '97843.p', '377975.p', '111782.p', '246259.p', '118016.p', '263310.p', '210831.p', '439887.p', '64156.p', '62826.p', '333391.p', '325101.p', '197518.p', '225227.p', '416414.p', '166175.p', '71156.p', '391562.p', '208048.p', '427669.p', '297589.p', '336520.p', '50716.p', '336935.p', '297312.p', '170401.p', '399016.p', '402885.p', '142515.p', '123469.p', '158412.p', '382023.p', '125971.p', '241672.p', '239291.p', '432601.p', '110697.p', '389374.p', '58342.p', '164457.p', '277773.p', '110939.p', '363444.p', '423440.p', '100493.p', '185401.p'], 'extremelyPoor': ['403169.p', '17535.p', '307007.p', '233280.p', '390187.p', '318977.p', '425999.p', '277647.p', '104112.p', '122203.p', '72226.p', '52560.p', '436227.p', '153308.p', '314269.p', '142159.p', '390913.p', '274152.p', '242184.p', '110517.p', '110540.p', '114259.p', '174159.p', '167199.p', '404030.p'], 'gradeA': ['191500.p', '343805.p', '103514.p', '310372.p', '60725.p', '6735.p', '58608.p', '398980.p', '261260.p', '336143.p', '221038.p', '2189.p', '167435.p', '228186.p', '160056.p', '102182.p', '119387.p', '422198.p', '131998.p', '438800.p']}\n"
     ]
    }
   ],
   "source": [
    "d = {'extremelyPoor':[],\n",
    "    'midRange':[],\n",
    "    'gradeA':[]\n",
    "    }\n",
    "for f in list(goodFileDict.keys())[0:350]:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        result = algo.predict(sentenceObj, dcsObj)\n",
    "        # try:\n",
    "            # if result == None:\n",
    "            #     print(f)\n",
    "        # except (ZeroDivisionError, IndexError) as e:\n",
    "        #     print(\"FROM HERE\")\n",
    "        #     result = None\n",
    "        #     pass\n",
    "        # except KeyError as e:\n",
    "        #     print(\"KeyError:\", e)\n",
    "        #     print(f)\n",
    "\n",
    "\n",
    "        if result != None:\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            if(ac < 20):\n",
    "                d['extremelyPoor'].append(f)\n",
    "            elif(ac > 30):\n",
    "                if(ac < 50):\n",
    "                    d['midRange'].append(f)\n",
    "                elif(ac > 80):\n",
    "                    d['gradeA'].append(f)\n",
    "                    \n",
    "            \n",
    "print()\n",
    "            \n",
    "print(len(d['extremelyPoor']))\n",
    "print(len(d['midRange']))\n",
    "print(len(d['gradeA']))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d['midRange'] = d['midRange'][0:15]\n",
    "d['extremelyPoor'] = d['extremelyPoor'][0:15]\n",
    "d['gradeA'] = d['gradeA'][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('ratedFiles.json','w') as fp:\n",
    "    json.dump(d, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extremelyPoor': ['403169.p',\n",
       "  '17535.p',\n",
       "  '307007.p',\n",
       "  '233280.p',\n",
       "  '390187.p',\n",
       "  '318977.p',\n",
       "  '425999.p',\n",
       "  '277647.p',\n",
       "  '104112.p',\n",
       "  '122203.p',\n",
       "  '72226.p',\n",
       "  '52560.p',\n",
       "  '436227.p',\n",
       "  '153308.p',\n",
       "  '314269.p'],\n",
       " 'gradeA': ['191500.p',\n",
       "  '343805.p',\n",
       "  '103514.p',\n",
       "  '310372.p',\n",
       "  '60725.p',\n",
       "  '6735.p',\n",
       "  '58608.p',\n",
       "  '398980.p',\n",
       "  '261260.p',\n",
       "  '336143.p',\n",
       "  '221038.p',\n",
       "  '2189.p',\n",
       "  '167435.p',\n",
       "  '228186.p',\n",
       "  '160056.p'],\n",
       " 'midRange': ['414970.p',\n",
       "  '318639.p',\n",
       "  '433875.p',\n",
       "  '217229.p',\n",
       "  '211085.p',\n",
       "  '273610.p',\n",
       "  '128515.p',\n",
       "  '110599.p',\n",
       "  '120991.p',\n",
       "  '427125.p',\n",
       "  '18461.p',\n",
       "  '198471.p',\n",
       "  '133458.p',\n",
       "  '63385.p',\n",
       "  '387288.p']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = json.load(open('ratedFiles.json'))\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO\n"
     ]
    }
   ],
   "source": [
    "d2 = {'extremelyPoor':[],\n",
    "    'midRange':[],\n",
    "    'gradeA':[]\n",
    "    }\n",
    "for f in d['gradeA']:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        try:\n",
    "            result, stat = algo.predictVerbose(sentenceObj, dcsObj)\n",
    "        except IndexError:\n",
    "            pass\n",
    "        # try:\n",
    "            # if result == None:\n",
    "            #     print(f)\n",
    "        # except (ZeroDivisionError, IndexError) as e:\n",
    "        #     print(\"FROM HERE\")\n",
    "        #     result = None\n",
    "        #     pass\n",
    "        # except KeyError as e:\n",
    "        #     print(\"KeyError:\", e)\n",
    "        #     print(f)\n",
    "\n",
    "\n",
    "        if result != None:\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            d2['gradeA'].append(stat)\n",
    "                \n",
    "for f in d['extremelyPoor']:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        try:\n",
    "            result, stat = algo.predictVerbose(sentenceObj, dcsObj)\n",
    "        except IndexError:\n",
    "            pass\n",
    "        # try:\n",
    "            # if result == None:\n",
    "            #     print(f)\n",
    "        # except (ZeroDivisionError, IndexError) as e:\n",
    "        #     print(\"FROM HERE\")\n",
    "        #     result = None\n",
    "        #     pass\n",
    "        # except KeyError as e:\n",
    "        #     print(\"KeyError:\", e)\n",
    "        #     print(f)\n",
    "\n",
    "\n",
    "        if result != None:\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            d2['extremelyPoor'].append(stat)\n",
    "            \n",
    "for f in d['midRange']:\n",
    "    sentenceObj, dcsObj = loadSentence(f, goodFileDict[f])\n",
    "    if(sentenceObj != None):\n",
    "        \n",
    "        result, stat = algo.predictVerbose(sentenceObj, dcsObj)\n",
    "        \n",
    "        # try:\n",
    "            # if result == None:\n",
    "            #     print(f)\n",
    "        # except (ZeroDivisionError, IndexError) as e:\n",
    "        #     print(\"FROM HERE\")\n",
    "        #     result = None\n",
    "        #     pass\n",
    "        # except KeyError as e:\n",
    "        #     print(\"KeyError:\", e)\n",
    "        #     print(f)\n",
    "\n",
    "\n",
    "        if result != None:\n",
    "            ac = Accuracy(result, dcsObj)\n",
    "            d2['midRange'].append(stat)\n",
    "print(\"GO\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'removed': [],\n",
       "  'winner': {'forms': [{'indeclinable': ['part.']}],\n",
       "   'lemmas': ['na'],\n",
       "   'names': 'na'}},\n",
       " '1': {'removed': [{'forms': [{'noun': ['voc. pl. m.']}],\n",
       "    'lemmas': ['sambhu'],\n",
       "    'names': 'sambhavas'}],\n",
       "  'winner': {'forms': [{'noun': ['nom. sg. m.']}, {'noun': ['nom. pl. m.']}],\n",
       "   'lemmas': ['sambhava', 'sambhu'],\n",
       "   'names': 'sambhavas'}},\n",
       " '2': {'removed': [],\n",
       "  'winner': {'forms': [{'verb': ['pr. [2] ac. sg. 3']}],\n",
       "   'lemmas': ['as_1'],\n",
       "   'names': 'asti'}},\n",
       " 'DCSLemma': [['sarva'], ['sarvatra'], ['sambhava'], ['na', 'as']],\n",
       " 'sentence': 'sarvasya sarvatra saMBavo nAsti   '}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2['gradeA'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('stat_15.json', 'w') as fp:\n",
    "    json.dump(d2, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradeA 15\n",
      "midRange 15\n",
      "extremelyPoor 15\n"
     ]
    }
   ],
   "source": [
    "for key, val in d2.items():\n",
    "    print(key, len(d2[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sImAvfkze nipatite kurURAM samitikzaye   \n",
      "Analyzing  sImAvfkze\n",
      "0 :  sImAs ['sImA'] [{'noun': ['acc. pl. f.', 'nom. pl. f.']}]\n",
      "0 :  sIma ['sIman'] [{'compound': ['iic.']}]\n",
      "0 :  sImA ['sImA', 'sIman'] [{'noun': ['nom. sg. f.']}, {'noun': ['nom. sg. m.', 'nom. sg. f.']}]\n",
      "3 :  a ['a'] [{'compound': ['iic.']}]\n",
      "4 :  vfkze ['vfkza'] [{'noun': ['loc. sg. m.']}]\n",
      "Analyzing  nipatite\n",
      "0 :  ni ['n'] []\n",
      "2 :  patite ['patta', 'pat_1'] [{'noun': ['acc. du. f.', 'nom. du. f.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.', 'loc. sg. m.']}, {'verb': ['pp.']}]\n",
      "2 :  patite ['patta', 'pat_1'] [{'noun': ['voc. du. f.', 'voc. sg. f.', 'voc. du. n.']}, {'verb': ['pp.']}]\n",
      "Analyzing  kurURAm\n",
      "0 :  kurURAm ['kuru'] [{'noun': ['g. pl. m.']}]\n",
      "Analyzing  samitikzaye\n",
      "0 :  samiti ['samt'] [{'compound': ['iic.']}]\n",
      "0 :  samiti ['samt'] [{'noun': ['loc. sg. f.']}]\n",
      "0 :  sa ['tad'] [{'noun': ['nom. sg. m.']}]\n",
      "0 :  sa ['sa_1'] [{'compound': ['iic.']}]\n",
      "9 :  ye ['ya_2'] [{'noun': ['acc. du. n.', 'nom. du. n.', 'loc. sg. n.', 'acc. du. f.', 'nom. du. f.']}]\n",
      "2 :  miti ['mt'] [{'compound': ['iic.']}]\n",
      "2 :  miti ['mt'] [{'indeclinable': ['ind.']}]\n",
      "6 :  kzaye ['kzaya_1', 'kzaya_2'] [{'noun': ['loc. sg. m.', 'acc. du. n.', 'nom. du. n.', 'loc. sg. n.', 'acc. du. f.', 'nom. du. f.']}, {'noun': ['loc. sg. m.']}]\n",
      "6 :  kzaye ['kzaya_1'] [{'noun': ['voc. du. n.', 'voc. du. f.', 'voc. sg. f.']}]\n",
      "6 :  kza ['kza'] [{'compound': ['iic.']}]\n"
     ]
    }
   ],
   "source": [
    "SeeSentence(sentenceObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
